{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyproj import Geod\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv',parse_dates=['pickup_time','drop_time'])\n",
    "test_df = pd.read_csv('../data/test.csv', parse_dates=['pickup_time','drop_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripid                         0\n",
       "additional_fare              202\n",
       "duration                     202\n",
       "meter_waiting                202\n",
       "meter_waiting_fare           202\n",
       "meter_waiting_till_pickup    202\n",
       "pickup_time                    0\n",
       "drop_time                      0\n",
       "pick_lat                       0\n",
       "pick_lon                       0\n",
       "drop_lat                       0\n",
       "drop_lon                       0\n",
       "fare                         137\n",
       "label                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs84_geod = Geod(ellps='WGS84')\n",
    "def Distance(lat1,lon1,lat2,lon2):\n",
    "  az12,az21,dist = wgs84_geod.inv(lon1,lat1,lon2,lat2)\n",
    "  return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_train = Distance(train_df.pick_lat.to_list(),\n",
    "                     train_df.pick_lon.to_list(),\n",
    "                     train_df.drop_lat.to_list(),\n",
    "                     train_df.drop_lon.to_list())\n",
    "\n",
    "distances_test = Distance(test_df.pick_lat.to_list(),\n",
    "                     test_df.pick_lon.to_list(),\n",
    "                     test_df.drop_lat.to_list(),\n",
    "                     test_df.drop_lon.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"distance\"]=distances_train\n",
    "test_df[\"distance\"]=distances_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickup timestamp\n",
    "train_df = train_df.assign(\n",
    "                            pickup_minute=test_df.pickup_time.dt.minute,\n",
    "                            pickup_hour=test_df.pickup_time.dt.hour,\n",
    "                            pickup_date=test_df.pickup_time.dt.day,\n",
    "                            pickup_day = test_df.pickup_time.dt.dayofweek,\n",
    "                            pickup_month=test_df.pickup_time.dt.month,\n",
    "                            pickup_year=test_df.pickup_time.dt.year\n",
    "                        )\n",
    "\n",
    "# drop timestamp\n",
    "test_df = test_df.assign(\n",
    "                            drop_minute=test_df.drop_time.dt.minute,\n",
    "                            drop_hour=test_df.drop_time.dt.hour,\n",
    "                            drop_date=test_df.drop_time.dt.day,\n",
    "                            drop_day = test_df.drop_time.dt.dayofweek,\n",
    "                            drop_month=test_df.drop_time.dt.month,\n",
    "                            drop_year=test_df.drop_time.dt.year,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[[\n",
    "    'additional_fare', \n",
    "    'duration',\n",
    "    'meter_waiting',\n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'distance',\n",
    "#     'pickup_hour',\n",
    "#     'pickup_minute',\n",
    "#     'drop_hour',\n",
    "#     'drop_minute'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'].replace(to_replace=['incorrect','correct'], value=[0,1],inplace=True)\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (13740, 7) (13740,)\n",
      "Test set: (3436, 7) (3436,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalable = [col for col in X_train.columns if \n",
    "                X_train[col].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scal_imput = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('simple_imputer', SimpleImputer(strategy='median')) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numeric\", scal_imput, scalable)\n",
    "    ],\n",
    "    remainder = \"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manusha/anaconda3/envs/my_env_35/lib/python3.5/site-packages/xgboost/__init__.py:28: FutureWarning: Python 3.5 support is deprecated; XGBoost will require Python 3.6+ in the near future. Consider upgrading to Python 3.6+.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, learning_rate=0.01, n_jobs=6, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('standard_scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  with_std=True)),\n",
       "                                                                  ('simple_imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing...\n",
       "                               interaction_constraints=None, learning_rate=0.01,\n",
       "                               max_delta_step=0, max_depth=5,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=1000,\n",
       "                               n_jobs=6, num_parallel_tree=1,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method=None,\n",
       "                               validate_parameters=False, verbosity=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.050058207217694994\n"
     ]
    }
   ],
   "source": [
    "score = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc f1  0.9791319527096722\n",
      "test acc 0.9499417927823051\n",
      "test acc f1  0.9728706624605679\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = pipeline.predict(X_train)\n",
    "print('train acc f1 ',f1_score(y_train,y_train_pred))\n",
    "print('test acc',accuracy_score(y_test,y_pred))\n",
    "print('test acc f1 ',f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "# imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# X= imp_mean.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isnan(X) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = StandardScaler().fit(X).transform(X.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# model = XGBClassifier(n_estimators=600, learning_rate=0.01, n_jobs=4, max_depth=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train,y_train)\n",
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error\n",
    "# score = mean_absolute_error(y_test, y_pred)\n",
    "# print('MAE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('train acc',accuracy_score(y_train,y_train_pred))\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# y_train_pred = model.predict(X_train)\n",
    "# print('train acc f1 ',f1_score(y_train,y_train_pred))\n",
    "# print('test acc',accuracy_score(y_test,y_pred))\n",
    "# print('test acc f1 ',f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = test_df[[\n",
    "    'additional_fare', \n",
    "    'duration',\n",
    "    'meter_waiting',\n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'distance',\n",
    "#     'pickup_hour',\n",
    "#     'pickup_minute',\n",
    "#     'drop_hour',\n",
    "#     'drop_minute'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8232\n",
       "0     344\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = pipeline.predict(X_)\n",
    "data = {'tripid':test_df['tripid'].values}\n",
    "df_res = pd.DataFrame(data)\n",
    "df_res['prediction'] = yhat\n",
    "df_res.to_csv('../data/xgboost_16.csv', index=False)\n",
    "df_res['prediction'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
